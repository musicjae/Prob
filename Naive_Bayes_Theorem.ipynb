{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes Theorem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdvwUVH5MtJ5SGBp9bSJGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musicjae/Prob/blob/master/Naive_Bayes_Theorem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tehgL6cfnqpy",
        "colab_type": "text"
      },
      "source": [
        "# 베이즈 정리  \n",
        "  \n",
        "베이즈 정리란 두 확률 변수의 사전 확률(관측자가 관측 전에 갖는 확률 분포)와 사후 확률 관계를 나타낸다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv8yzn1yn0GV",
        "colab_type": "text"
      },
      "source": [
        "# 베이즈 추정  \n",
        "  \n",
        "표본만을 통해 모수를 추정하는 것 보다, 표본 정보 & 사전 정보 둘다 사용하여 모수를 추정하는 것이 더 바람직할 것이다.  \n",
        "  \n",
        "추론 대상을 $\\theta$, 관측되는 대상을 $X$라고 해보자.  \n",
        "  \n",
        "그러면, $P(\\theta|X)=\\frac{P(\\theta,X)}{P(X)}=\\frac{P(X|\\theta)P(\\theta)}{P(\\theta)}$이다.  \n",
        "  \n",
        "- $p(X|\\theta)$는 $\\theta$로부터 관측된 X의 확률 분포  \n",
        "  \n",
        "- $P(\\theta)$는 사전 확률  \n",
        "  \n",
        "- $P(X)$는 관측 대상 X에 대한 확률  \n",
        "  \n",
        "- 위 베이즈 추론 식에서 두 번째 항에서 세 번째 항으로 넘어가는 과정에 대한 상세화:  \n",
        "$$P(X|\\theta)=\\frac{P(X,\\theta)}{P(\\theta)} \\iff P(X,\\theta) = P(X|\\theta)P(\\theta)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yPtdmX0pM86",
        "colab_type": "text"
      },
      "source": [
        "# 나이브 베이즈 분류기  \n",
        "  \n",
        "이것은 일종의 지도학습이다. 이것은 빠르고, 비교적 정확한 성능을 보인다. 이것은 features 간의 독립성을 요구한다는 특징을 지닌다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG50tAhsnkQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fight=['fight','no','fight','no','no','no','no','no','fight','no','no','no','fight','no']\n",
        "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
        "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
        "dec=['go_home','go_out','go_home','go_home','go_home','go_out','go_home','go_home','go_out','go_home','go_home','go_out''go_home','go_home','go_out']\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YmZUAs_tbgU",
        "colab_type": "text"
      },
      "source": [
        "String -> Int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss43v1vPskqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3269a8cb-9730-4012-e978-56c0ebe435eb"
      },
      "source": [
        "# Import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#creating labelEncoder\n",
        "le = preprocessing.LabelEncoder()\n",
        "print(le)\n",
        "\n",
        "# Converting string labels into numbers.\n",
        "weather_encoded=le.fit_transform(weather)\n",
        "fight_encoded = le.fit_transform(fight)\n",
        "label = le.fit_transform(dec)\n",
        "print('weather_encoded:',weather_encoded,'\\n\\n','fight_encoded',fight_encoded,'\\n\\n','(label) dec_encoded',label)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LabelEncoder()\n",
            "weather_encoded: [2 2 0 1 1 1 0 2 2 1 2 0 0 1] \n",
            "\n",
            " fight_encoded [0 1 0 1 1 1 1 1 0 1 1 1 0 1] \n",
            "\n",
            " (label) dec_encoded [0 1 0 0 0 1 0 0 1 0 0 2 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw2r7C9tuGrS",
        "colab_type": "text"
      },
      "source": [
        "인코딩 된 두 특성 (날씨, 싸움 여부)를 결합"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzgK7ScauKkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e44d197-9bde-47ad-f434-cbfd591f1ed9"
      },
      "source": [
        "#Combinig weather and temp into single listof tuples\n",
        "features = zip(weather_encoded,fight_encoded)\n",
        "features = list(features)\n",
        "print(features)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(2, 0), (2, 1), (0, 0), (1, 1), (1, 1), (1, 1), (0, 1), (2, 1), (2, 0), (1, 1), (2, 1), (0, 1), (0, 0), (1, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP9so-oXuS6L",
        "colab_type": "text"
      },
      "source": [
        "나이브 분류기 모델  \n",
        "  \n",
        "모델 생성 -> 훈련 데이터 Fitting -> 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyP6X8-suVgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6295efb-493f-44f0-9378-25bfecb08955"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(features,label)\n",
        "\n",
        "#Predict Output\n",
        "predicted= model.predict([[2,0]]) # 0:Overcast, 2:Mild\n",
        "print(\"Predicted Value:\", predicted) # 1: Yes\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Value: [0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDugInZAvgUe",
        "colab_type": "text"
      },
      "source": [
        "### 여러 class에 대한 나이브 베이즈 분류기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HgD5iGMvqgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "14db3e2f-97d6-4f55-fbef-4e484b0bb265"
      },
      "source": [
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "bc = datasets.load_breast_cancer()\n",
        "\n",
        "# print the names of the 13 features\n",
        "print(\"Features: \", bc.feature_names,'\\n\\n',bc.feature_names.size)\n",
        "\n",
        "# print the label type of wine(class_0, class_1, class_2)\n",
        "print(\"\\n\\nLabels: \", bc.target_names,'\\n\\n',bc.target_names.size)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension'] \n",
            "\n",
            " 30\n",
            "\n",
            "\n",
            "Labels:  ['malignant' 'benign'] \n",
            "\n",
            " 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhaOkAmRwWl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a196f25c-49bf-4b07-d1c2-11b0e0c41842"
      },
      "source": [
        "bc.data.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHHkA5Vawm_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c05984b-8d7e-4bb1-e6a7-c329d28b3c1f"
      },
      "source": [
        "bc.target[0:5]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sij1VJ_IwsQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0a367687-3279-4a7c-b831-984f4373a4d0"
      },
      "source": [
        "bc.data[0:1]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
              "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
              "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
              "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
              "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG83yjKXxBZb",
        "colab_type": "text"
      },
      "source": [
        "훈련셋, 테스트셋으로 나눈 뒤 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf-EnXUzw0VC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4428ee1a-ebfe-40e4-8c8f-27bf6c4282a1"
      },
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "# 80% training and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(bc.data, bc.target, test_size=0.2, random_state=109)\n",
        "\n",
        "# 70% training and 20% test\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(bc.data, bc.target, test_size=0.3, random_state=109)\n",
        "\n",
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "#Train the model using the training sets\n",
        "gnb.fit(X_train, y_train)\n",
        "gnb.fit(X2_train, y2_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}